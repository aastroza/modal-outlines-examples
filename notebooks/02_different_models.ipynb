{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from modal import Cls\n",
    "from textwrap import dedent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "schema = '''{\n",
    "    \"title\": \"Character\",\n",
    "    \"type\": \"object\",\n",
    "    \"properties\": {\n",
    "        \"name\": {\n",
    "            \"title\": \"Name\",\n",
    "            \"maxLength\": 20,\n",
    "            \"type\": \"string\"\n",
    "        },\n",
    "        \"age\": {\n",
    "            \"title\": \"Age\",\n",
    "            \"type\": \"integer\"\n",
    "        },\n",
    "        \"armor\": {\"$ref\": \"#/definitions/Armor\"},\n",
    "        \"weapon\": {\"$ref\": \"#/definitions/Weapon\"},\n",
    "        \"strength\": {\n",
    "            \"title\": \"Strength\",\n",
    "            \"type\": \"integer\"\n",
    "        }\n",
    "    },\n",
    "    \"required\": [\"name\", \"age\", \"armor\", \"weapon\", \"strength\"],\n",
    "    \"definitions\": {\n",
    "        \"Armor\": {\n",
    "            \"title\": \"Armor\",\n",
    "            \"description\": \"An enumeration.\",\n",
    "            \"enum\": [\"leather\", \"chainmail\", \"plate\", \"cape\", \"poncho\"],\n",
    "            \"type\": \"string\"\n",
    "        },\n",
    "        \"Weapon\": {\n",
    "            \"title\": \"Weapon\",\n",
    "            \"description\": \"An enumeration.\",\n",
    "            \"enum\": [\"sword\", \"axe\", \"mace\", \"spear\", \"bow\", \"crossbow\", \"wand\", \"charango\"],\n",
    "            \"type\": \"string\"\n",
    "        }\n",
    "    }\n",
    "}'''\n",
    "\n",
    "prompt = \"Give me a character description\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mistral"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_template = dedent(\n",
    "                            \"\"\"\\\n",
    "                        <s>[INST]\n",
    "                        A user is gonna ask you a question.\n",
    "                        You must answer the user's question by replying VALID JSON that matches the schema below:\n",
    "                        \n",
    "                        ```json\n",
    "                        {schema}\n",
    "                        ```\n",
    "                        \n",
    "                        ---\n",
    "                        \n",
    "                        The user's question below\n",
    "                        \n",
    "                        ```text\n",
    "                        {question}\n",
    "                        ```\n",
    "                        \n",
    "                        [/INST]\n",
    "                        \"\"\")\n",
    "Model = Cls.lookup(\"outlines-app\", \"Model\")\n",
    "m_mistral = Model(model_name=\"mistralai/Mistral-7B-Instruct-v0.2\")\n",
    "result = m_mistral.generate.remote(schema.strip(), prompt_template.format(schema=schema.strip(), question=prompt))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'name': 'John Doe',\n",
       " 'age': 35,\n",
       " 'armor': 'chainmail',\n",
       " 'weapon': 'sword',\n",
       " 'strength': 50}"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompts = [\"Give me a funny character description\",\n",
    "           \"Give me a chilean character description\",\n",
    "           \"Someone from Harry Potter universe\",\n",
    "           \"Who you gonna call?\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'name': 'Bloop the Legendary', 'age': 300, 'armor': 'cape', 'weapon': 'charango', 'strength': 12}\n",
      "{'name': 'Pedro Valdez', 'age': 35, 'armor': 'poncho', 'weapon': 'charango', 'strength': 50}\n",
      "{'name': 'Harry Potter', 'age': 34, 'armor': 'cape', 'weapon': 'wand', 'strength': 10}\n",
      "{'name': 'Ghostbusters Team', 'age': 35, 'armor': 'cape', 'weapon': 'wand', 'strength': 100}\n"
     ]
    }
   ],
   "source": [
    "for p in prompts:\n",
    "    print(m_mistral.generate.remote(schema.strip(), prompt_template.format(schema=schema.strip(), question=p)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gemma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "gemma_prompt_template = dedent(\n",
    "                        \"\"\"\n",
    "                    <bos><start_of_turn>user\\n\n",
    "                    A user is gonna ask you a question.\\n\n",
    "                    You must answer the user's question by replying VALID JSON that matches the schema below:\\n\n",
    "                    ```json\\n\n",
    "                    {schema}\\n\n",
    "                    ```\\n\n",
    "                    The user's question below:\\n\n",
    "                    ```text\\n\n",
    "                    {question}\\n\n",
    "                    ```\\n\n",
    "                    <end_of_turn>\\n\n",
    "                    <start_of_turn>model\\n\n",
    "                    \"\"\")\n",
    "Model = Cls.lookup(\"outlines-app\", \"Model\")\n",
    "m_gemma = Model(model_name=\"google/codegemma-7b-it\")\n",
    "result = m_gemma.generate.remote(schema.strip(),\n",
    "                                 gemma_prompt_template.format(schema=schema.strip(), question=prompt))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'name': 'John Doe',\n",
       " 'age': 30,\n",
       " 'armor': 'plate',\n",
       " 'weapon': 'sword',\n",
       " 'strength': 10}"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'name': 'Sir Snortly McCrack', 'age': 42, 'armor': 'cape', 'weapon': 'wand', 'strength': 1}\n",
      "{'name': 'Pedro Cardenal', 'age': 25, 'armor': 'leather', 'weapon': 'sword', 'strength': 15}\n",
      "{'name': 'Harry Potter', 'age': 17, 'armor': 'cape', 'weapon': 'wand', 'strength': 10}\n",
      "{'name': 'Doctor Who', 'age': 900, 'armor': 'cape', 'weapon': 'wand', 'strength': 1000}\n"
     ]
    }
   ],
   "source": [
    "for p in prompts:\n",
    "    print(m_gemma.generate.remote(schema.strip(),\n",
    "                                  gemma_prompt_template.format(schema=schema.strip(), question=p)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deepseek"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "deepseek_prompt_template = dedent(\"\"\"\\\n",
    "                        A user is gonna ask you a question.\n",
    "                        You must answer the user's question by replying VALID JSON that matches the schema below:\n",
    "                        \n",
    "                        ```json\n",
    "                        {schema}\n",
    "                        ```\n",
    "                        \n",
    "                        ---\n",
    "                        \n",
    "                        The user's question below\n",
    "                        \n",
    "                        ```text\n",
    "                        {question}\n",
    "                        ```\n",
    "                        \"\"\"\n",
    "                        )\n",
    "Model = Cls.lookup(\"outlines-app\", \"Model\")\n",
    "m_deepseek = Model(model_name=\"deepseek-ai/deepseek-coder-7b-instruct-v1.5\")\n",
    "result = m_deepseek.generate.remote(schema.strip(),\n",
    "                                 deepseek_prompt_template.format(schema=schema.strip(), question=prompt))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'name': 'NinjaKnight',\n",
       " 'age': 30,\n",
       " 'armor': 'chainmail',\n",
       " 'weapon': 'sword',\n",
       " 'strength': 90}"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'name': 'Boba Fett', 'age': 46, 'armor': 'cape', 'weapon': 'sword', 'strength': 90}\n",
      "{'name': 'Guille', 'age': 25, 'armor': 'leather', 'weapon': 'sword', 'strength': 86}\n",
      "{'name': 'Harry Potter', 'age': 15, 'armor': 'chainmail', 'weapon': 'sword', 'strength': 10}\n",
      "{'name': '', 'age': 0, 'armor': 'leather', 'weapon': 'sword', 'strength': 100}\n"
     ]
    }
   ],
   "source": [
    "for p in prompts:\n",
    "    print(m_deepseek.generate.remote(schema.strip(),\n",
    "                                  deepseek_prompt_template.format(schema=schema.strip(), question=p)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mixtral"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mixtral_prompt_template = dedent(\n",
    "                            \"\"\"\\\n",
    "                        <s>[INST]\n",
    "                        A user is gonna ask you a question.\n",
    "                        You must answer the user's question by replying VALID JSON that matches the schema below:\n",
    "                        \n",
    "                        ```json\n",
    "                        {schema}\n",
    "                        ```\n",
    "                        \n",
    "                        ---\n",
    "                        \n",
    "                        The user's question below\n",
    "                        \n",
    "                        ```text\n",
    "                        {question}\n",
    "                        ```\n",
    "                        \n",
    "                        [/INST]\n",
    "                        \"\"\")\n",
    "Model = Cls.lookup(\"outlines-app\", \"Model\")\n",
    "m_mixtral = Model(model_name=\"mistralai/Mixtral-8x7B-Instruct-v0.1\")\n",
    "result = m_mixtral.generate.remote(schema.strip(), mixtral_prompt_template.format(schema=schema.strip(), question=prompt))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for p in prompts:\n",
    "    print(m_mixtral.generate.remote(schema.strip(),\n",
    "                                  mixtral_prompt_template.format(schema=schema.strip(), question=p)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Glaive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name '_expand_mask' from 'transformers.models.bloom.modeling_bloom' (/usr/local/lib/python3.11/site-packages/transformers/models/bloom/modeling_bloom.py)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[24], line 9\u001b[0m\n\u001b[0;32m      7\u001b[0m Model \u001b[38;5;241m=\u001b[39m Cls\u001b[38;5;241m.\u001b[39mlookup(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124moutlines-app\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mModel\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m      8\u001b[0m m_glaive \u001b[38;5;241m=\u001b[39m Model(model_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mglaiveai/glaive-function-calling-v1\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m----> 9\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[43mm_glaive\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgenerate\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mremote\u001b[49m\u001b[43m(\u001b[49m\u001b[43mschema\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstrip\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     10\u001b[0m \u001b[43m                                 \u001b[49m\u001b[43mglaive_prompt_template\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mformat\u001b[49m\u001b[43m(\u001b[49m\u001b[43mschema\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mschema\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstrip\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mquestion\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprompt\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Alonso\\anaconda3\\envs\\modal-outlines-examples\\Lib\\site-packages\\synchronicity\\synchronizer.py:531\u001b[0m, in \u001b[0;36mSynchronizer._wrap_proxy_method.<locals>.proxy_method\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    529\u001b[0m instance \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__dict__\u001b[39m[synchronizer_self\u001b[38;5;241m.\u001b[39m_original_attr]\n\u001b[0;32m    530\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 531\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mwrapped_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43minstance\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    532\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m UserCodeException \u001b[38;5;28;01mas\u001b[39;00m uc_exc:\n\u001b[0;32m    533\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m uc_exc\u001b[38;5;241m.\u001b[39mexc \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Alonso\\anaconda3\\envs\\modal-outlines-examples\\Lib\\site-packages\\synchronicity\\combined_types.py:28\u001b[0m, in \u001b[0;36mFunctionWithAio.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m     26\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m     27\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m UserCodeException \u001b[38;5;28;01mas\u001b[39;00m uc_exc:\n\u001b[1;32m---> 28\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m uc_exc\u001b[38;5;241m.\u001b[39mexc \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32m<ta-01HVWTT8SN3WSY2ED66040GZXG>:/pkg/synchronicity/synchronizer.py:531\u001b[0m, in \u001b[0;36mproxy_method\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32m<ta-01HVWTT8SN3WSY2ED66040GZXG>:/pkg/synchronicity/synchronizer.py:422\u001b[0m, in \u001b[0;36mf_wrapped\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32m<ta-01HVWTT8SN3WSY2ED66040GZXG>:/pkg/modal/cls.py:85\u001b[0m, in \u001b[0;36mget_obj\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32m<ta-01HVWTT8SN3WSY2ED66040GZXG>:/pkg/modal/cls.py:79\u001b[0m, in \u001b[0;36m<lambda>\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32m<ta-01HVWTT8SN3WSY2ED66040GZXG>:/root/different_models.py:19\u001b[0m, in \u001b[0;36m__init__\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32m<ta-01HVWTT8SN3WSY2ED66040GZXG>:/usr/local/lib/python3.11/site-packages/outlines/models/transformers.py:224\u001b[0m, in \u001b[0;36mtransformers\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32m<ta-01HVWTT8SN3WSY2ED66040GZXG>:/usr/local/lib/python3.11/site-packages/transformers/models/auto/auto_factory.py:548\u001b[0m, in \u001b[0;36mfrom_pretrained\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32m<ta-01HVWTT8SN3WSY2ED66040GZXG>:/usr/local/lib/python3.11/site-packages/transformers/dynamic_module_utils.py:500\u001b[0m, in \u001b[0;36mget_class_from_dynamic_module\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32m<ta-01HVWTT8SN3WSY2ED66040GZXG>:/usr/local/lib/python3.11/site-packages/transformers/dynamic_module_utils.py:200\u001b[0m, in \u001b[0;36mget_class_in_module\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32m<ta-01HVWTT8SN3WSY2ED66040GZXG>:/usr/local/lib/python3.11/importlib/__init__.py:126\u001b[0m, in \u001b[0;36mimport_module\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32m<frozen importlib._bootstrap>:1206\u001b[0m, in \u001b[0;36m_gcd_import\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32m<frozen importlib._bootstrap>:1178\u001b[0m, in \u001b[0;36m_find_and_load\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32m<frozen importlib._bootstrap>:1149\u001b[0m, in \u001b[0;36m_find_and_load_unlocked\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32m<frozen importlib._bootstrap>:690\u001b[0m, in \u001b[0;36m_load_unlocked\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32m<frozen importlib._bootstrap_external>:940\u001b[0m, in \u001b[0;36mexec_module\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32m<frozen importlib._bootstrap>:241\u001b[0m, in \u001b[0;36m_call_with_frames_removed\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32m/root/.cache/huggingface/modules/transformers_modules/glaiveai/glaive-function-calling-v1/d94dd60c9ceaff581cf7e6b5f9982b4b1716ae16/modeling_mpt.py:18\u001b[0m\n",
      "File \u001b[1;32m/root/.cache/huggingface/modules/transformers_modules/glaiveai/glaive-function-calling-v1/d94dd60c9ceaff581cf7e6b5f9982b4b1716ae16/hf_prefixlm_converter.py:15\u001b[0m\n",
      "\u001b[1;31mImportError\u001b[0m: cannot import name '_expand_mask' from 'transformers.models.bloom.modeling_bloom' (/usr/local/lib/python3.11/site-packages/transformers/models/bloom/modeling_bloom.py)"
     ]
    }
   ],
   "source": [
    "glaive_prompt_template = dedent(\n",
    "                                \"\"\"\\\n",
    "                                SYSTEM: You are an helpful assistant who has access to the following functions to help the user, you can use the functions if needed-\n",
    "                                {schema}\\n\n",
    "                                USER: {question}\\n\n",
    "                                \"\"\")\n",
    "Model = Cls.lookup(\"outlines-app\", \"Model\")\n",
    "m_glaive = Model(model_name=\"glaiveai/glaive-function-calling-v1\")\n",
    "result = m_glaive.generate.remote(schema.strip(),\n",
    "                                 glaive_prompt_template.format(schema=schema.strip(), question=prompt))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for p in prompts:\n",
    "    print(m_glaive.generate.remote(schema.strip(),\n",
    "                                  glaive_prompt_template.format(schema=schema.strip(), question=p)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "modal-outlines-examples",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
